
\titleformat{\chapter}{\bf \huge}{\thechapter}{1cm}{}
\chapter{Early Career Spotlight}

\vspace{-1.5cm}
\invitedTalk{Julie A. Shah}{Integrating Robots into Team-Oriented Environments}{MIT}{Wednesday, July 16, 15:00}{shah.jpg}
{
Recent advances in computation, sensing, and hardware enable robotics to perform an increasing percentage of traditionally manual tasks in manufacturing. Yet, often the assembly mechanic cannot be removed entirely from the process. This provides new economic motivation to explore opportunities where human workers and industrial robots may work in close physical collaboration. In this talk, I will present the development of new algorithmic techniques for collaborative plan execution that scale to real-world industrial applications. I also discuss the design of new models for robot planning, which use insights and data derived from the planning and execution strategies employed by successful human teams, to support more seamless robot participation in human work practices. This includes models for human-robot team training, which involves hands-on practice to clarify sequencing and timing of actions, and for team planning, which includes communication to negotiate and clarify allocation and sequencing of work. The aim is to support both the human and robot workers in co-developing a common understanding of task responsibilities and information requirements, to produce more effective human-robot partnerships.
}{
Julie Shah is an Assistant Professor in the Department of Aeronautics and Astronautics at MIT and leads the Interactive Robotics Group of the Computer Science and Artificial Intelligence Laboratory. Shah received her SB (2004) and SM (2006) from the Department of Aeronautics and Astronautics at MIT, and her PhD (2010) in Autonomous Systems from MIT. Before joining the faculty, she worked at Boeing Research and Technology on robotics applications for aerospace manufacturing. She has developed innovative methods for enabling fluid human-robot teamwork in time-critical, safety-critical domains, ranging from manufacturing to surgery to space exploration. Her group draws on expertise in artificial intelligence, human factors, and systems engineering to develop interactive robots that emulate the qualities of effective human team members to improve the efficiency of human-robot teamwork. Shah is the recipient of a 2014 NSF CAREER Award, and her work was recognized by the Technology Review as one of the 10 Breakthrough Technologies of 2013. She has received international recognition in the form of best paper awards and nominations from the International Conference on Automated Planning and Scheduling, the American Institute of Aeronautics and Astronautics, the IEEE/ACM International Conference on Human-Robot Interaction, and the International Symposium on Robotics.
}


\invitedTalk{Ashutosh Saxena}{Scaling Robotics: Perception, Planning and Language}{Cornell University}{Wednesday, July 16, 15:30}{saxena.jpg}
{
For building future robotic applications, robots need to learn from multi-modal data such as images, videos, 3D point-clouds, video game logs and natural language.  How can such robot learning be scaled to thousands and even millions of examples?   

In this talk, I will present learning algorithms that start learning from large-scale unsupervised datasets, and through different forms of human feedback learn about concepts such as object affordances and basic physics.  Through a few examples, I will show that such learning is very effective in performing a variety of tasks including 3D scene labeling, human activity detection and ancipatoon, grasping and path planning, language understanding, and so on.

}{
Ashutosh Saxena is an assistant professor in the Computer Science department at Cornell University. His research interests include machine learning, robotics and computer vision. He received his MS in 2006 and Ph.D. in 2009 from Stanford University with Prof. Andrew Ng, and his B.Tech. in 2004 from Indian Institute of Technology (IIT) Kanpur.  He was named a co-chair of IEEE technical committee on robot learning and is an associate editor of IEEE Transactions of Robotics. He was a recipient of National Talent Scholar award in India and Google Faculty award in 2011. He was named a Alred P. Sloan Fellow in 2011, named a Microsoft Faculty Fellow in 2012, received a NSF Career award in 2013, and received Early Career Spotlight Award at RSS 2014.
He has developed learning algorithms for capturing rich context from multi-modal data such as images, videos, 3D point clouds and natural language.  His algorithms have enabled several robots to perform a variety of tasks, for example:  his single image depth estimation (Make3D) algorithm has enabled aerial robots to fly; his human behavior modeling algorithm (`hallucinating humans') has enabled robots to detect objects in 3D scenes, anticipate human actions, and underwrite non-prime financial lending; his co-active learning algorithm has enabled manipulators to plan user preferred motions.  His robots (such as STAIR, POLAR and Kodiak) perform household chores such as unload items from a dishwasher, arrange a disorganized house, and cook simple kitchen recipes. His work has received a lot of attention in the popular press such as the frontage of New York Times, BBC, ABC, New Scientist, Discovery Science, Wired Magazine and many others.
}
