%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Invited Talks}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%some helper commands for common formatting:
\newcommand{\invitedTalk}[7]{
 \begin{minipage}[t]{0.48\textwidth}
 \vspace{1em}
 \begingroup
  \sf
  {\Large #4\\}
  {\LARGE #1\\}
  \begin{spacing}{1.0}

     {\LARGE \raggedright #2}
     
  \end{spacing}
  %\vspace{5mm}
  \endgroup
  \normalsize
  #6
  
 \end{minipage}
 ~\hfill~
 \begin{minipage}[t]{0.43\textwidth}
  \begin{flushright}
   \vspace{1em}
     \ifthenelse { \equal{#5}{} } {
	%\vspace{2cm}
     } {
              \includegraphics[height=5cm]{local_img/speakers/#5}\\
     }
     \textbf{#1}\\
     #3 \\[5mm]
  \end{flushright}
  {\small \textbf{Biography}
  
  #7
  
  }
\end{minipage}
\vspace{1cm}
%\clearpage

}


\vspace{-2cm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\invitedTalk{Alyosha Ephros}{Her Majesty the Data}{Carnegie Mellon University}{Monday, June 24, 09:00}{ephros.jpg}
{
While the term "Big Data" has only recently come into vogue, it can be argued that many of the practical advances in challenging fields like computer vision have been driven by increasing the amount of data used, rather than any specific algorithmic innovation.  The reason for this seems to be the sheer complexity of our (visual) world; it may simply be too rich to be well represented by compact parametric models.  In this talk, I will use the visual domain as an example to illustrate the benefits of heavily data-driven approaches. Particularly, with the abundance of data, one can move away from representations based on rigid categories and toward these based on unsupervised (or semi-supervised) data association. That is, we would like the data to "speak its own mind", instead of being beaten into submission by often-arbitrary category labels.  The main challenge in the case of high-dimensional visual (and other sensory) data is establishing distance metrics that can capture our perception of visual 
similarity.  I~will present some of our recent work in this direction, with applications to visual geo-location, object detection, and visual data mining.  I~will also briefly discuss some of the dangers of Big Data, particularly the issue of dataset bias.
}{
Alexei "Alyosha" Efros is an associate professor at the Robotics Institute and the Computer Science Department at Carnegie Mellon University. His research is in the area of computer vision and computer graphics, especially at the intersection of the two. He is particularly interested in using data-driven techniques to tackle problems which are very hard to model parametrically but where large quantities of data are readily available. Alyosha received his PhD in 2003 from UC Berkeley under Jitendra Malik and spent the following year as a post-doctoral fellow in Andrew Zisserman's group in Oxford, England. Alyosha is a recipient of CVPR Best Paper Award (2006), NSF CAREER award (2006), Sloan Fellowship (2008), Guggenheim Fellowship (2008), Okawa Grant (2008), Finmeccanica Career Development Chair (2010), SIGGRAPH Significant New Researcher Award (2010), and ECCV Best Paper Honorable Mention (2010).
}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\invitedTalk{Raffaello d'Andrea}{Actuated Wingsuits for Unconstrained Human Flight}{ETH Z\"urich}{Monday, June 24, 13:30}{dandrea.png}
{
Human flight has been an incredible driving force for human innovation. From early epics like the story of Icarus, to Leonardo da Vinci's designs of hang gliders and helicopters, and from the Wright brothers’ first planes to our first trip to the moon, human flight has accompanied and inspired us throughout much of our scientific and technological history. The field has made spectacular advances since its inception and now permeates modern systems of everyday life, from aerial photography to air ambulances and commercial air travel. For many of us, however, human flight has now become a necessity rather than a source of inspiration, evoking visions of crowded cabins with cramped seating and tiny windows.

In this talk I will discuss research that connects in spirit and ambition to the man-on-the-moon type projects on human flight that have so successfully fuelled human inventiveness and innovation in the past: unconstrained human flight. By building on existing wingsuit technology and by leveraging research on light-weight structures and propulsion systems, non-equilibrium aerodynamics, novel sensors and actuators, and algorithmic methods for the control of highly dynamic systems, we seek to create an actuated wingsuit that can be actively controlled by the flyer, allowing individuals to take off and land at will, to gain altitude, even to perch, while preserving the intimacy of wingsuit flight.
}{
Spanning academics, business and the arts, Raffaello D'Andrea's career is built on his ability to bridge theory and practice: He is Professor of Dynamic Systems and Control at the Swiss Federal Institute of Technology (ETH) in Zurich, where his research redefines what autonomous systems are capable of. He is also co-founder of Kiva Systems (recently acquired by Amazon), a robotics and logistics company that develops and deploys intelligent automated warehouse systems. In addition, he is an internationally-exhibited new media artist, best known for the Robotic Chair (Ars Electronica, ARCO, London Art Fair, National Gallery of Canada) and Flight Assembled Architecture (FRAC Centre, France). Other creations and projects include the Flying Machine Arena, the Distributed Flight Array, the Blind Juggler, the Balancing Cube, and RoboEarth.
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\invitedTalk{Julia Parrish}{Life Lessons: Are Animal Aggregations Appropriate Models for Robotics?}{University of Washington}{Wednesday, June 26, 09:00}{parish.jpg}
{
Why copy nature? And what should be copied? Beyond materials and structural elements is behavior. Mobile organisms engage in a broad range of behaviors, and one of the most common is aggregation. From bacteria and slime molds to starlings, tuna, and people, mobile organisms form dense, structured, and fluid arrangements where the decisions of any one individual will also depend on, and be altered by, the responses of its neighbors. The ultimate decentralized intelligence, animal aggregations can efficiently perform tasks individuals cannot easily complete, including reconnaissance, signal detection, architecture, defense, avoidance, coordination, subjugation, and collective memory/history. Would robots swarms modeled on animal aggregations be more efficient?

Aggregation supposes a degree of cooperation and coordination among group members – an agreed upon rule set. But individual organisms make ‘selfish’ decisions, optimizing their long-term rewards (or their ability to survive and reproduce) at the potential expense of others. Thus, there is a dynamic between the competitive nature of selfish individuals and the cooperative necessities of coordinated group activities. Shifts in emergent function can be imposed by the insertion of group members with different sensors, different task sets, or different levels of experience. Innovators – those with lower latency, or higher risk tolerance – can steer group response, even as a minority. Maintaining a range of individual diversity allows the group to be responsive under shifting conditions. But quorum responses can also suppress individual knowledge, occasionally leading to propagation of incorrect or inappropriate responses given a changing environment. This paper explores how and why animal aggregations work, what 
problems aggregation solves, and the opportunities and constraints of the biomimicry of behavior.
}{
Julia K. Parrish is the Associate Dean of the College of the Environment at the University of Washington, where she holds a Professor in the School of Aquatic and Fishery Sciences, and in the Biology Department.  She is an elected Fellow of the American Ornithological Union, and a recipient of the NOAA Environmental Hero Award.  Her research has focused on group dynamics, and in particular an exploration of the costs, benefits, and traffic rules of schooling fish.  Julia is the lead editor of Animal Groups in Three Dimensions (Cambridge), a seminal text bringing together field, laboratory, and computational approaches to the study of aggregation; and has authored a wide range of articles on fish schooling.
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\invitedTalk{Rodney Brooks}{Robotics Research Just Got A Whole Lot More Exciting}{Rethink Robotics}{Tuesday, June 25, 09:00}{brooks.jpg}
{
The proliferation of low cost safe research platforms for mobile robots led to SLAM and to the now popular perception that the idea of human drivers of automobiles will be quaint and retro within most people's life times. Finally we are starting to see low cost generally available and safe multi-arm robots. The possibilities for innovation and new directions are hard to know -- but we can know that the research community will come up with ideas that no one can now dare to imagine. And just in time. Demographics is going to demand some good robot ideas and applications.
}{
Rodney Brooks is founder, CTO, and Chairman of Rethink Robotics, a 2008 Boston-based startup. The company is developing a new class of industrial robot that will help keep manufacturing jobs in America. Rethink's robots are to current industrial robots what the PC was to the mainframe.  The new robots are made in the USA.

Brooks was also a co-founder of iRobot (Nasdaq: IRBT) and was variously CTO, Chairman, and board member from 1990 until 2011. From 1984 to 2010 he was on the faculty at MIT as the Panasonic Professor of Robotics, and was the director of MIT CSAIL, the Computer Science and Artificial Intelligence Laboratory.  While at MIT he developed the behavior-based approach to robotics that underlies the robots of both iRobot and Rethink Robotics.
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\invitedTalk{Neil Burgess}{Neural mechanisms of spatial navigation}{University College London}{Wednesday, June 26, 13:30}{burgess.jpg}
{
Electrophysiological recordings from neurons in the hippocampal and entorhinal cortices of freely moving rodents provide detailed information regarding the neural representations of spatial location and orientation. I will describe some of these experiments and the computational mechanisms they imply, which emphasise the roles of environmental boundaries, intrinsic temporal oscillations in the theta band and attractor dynamics. I will then describe the implications of these findings for the mechanisms supporting human spatial memory, and provide examples of electrophysiological, behavioural, neuropsychological and functional neuroimaging experiments designed to test the resulting predictions.
}{
Neil Burgess is Professor of cognitive and computational neuroscience and a Wellcome Trust Principal Research Fellow at the UCL Institute of Cognitive Neuroscience. His laboratory investigates the neural mechanisms of memory using a combination of methods including computational modeling, human neuropsychology and functional neuroimaging and single unit recordings in freely moving rodents. His main goal is to understand how the actions of networks of neurons in our brains allow us to remember events and the spatial locations where they occurred. After studying Maths and Physics at UCL he did a PhD in Theoretical Physics in Manchester and a research fellowship in Rome, before returning to UCL funded a Royal Society University Research Fellowship, and a Medical Research Council Senior Research Fellowship. 
}


\chapter{Early Career Spotlight}

\invitedTalk{Siddhartha Srinivasa}{The Mathematics of Human Robot Interaction}{Carnegie Mellon University}{Monday, June 24, 15:30}{srinivasa.jpg}
{
For years, the focus of robot motion planning has been to produce functional motion: industrial robots move to weld parts, vacuuming robots move to suck dust, and personal robots move to clean up a dirty table. We have been exploring the thesis that although functional motion is ideal when robots perform tasks in isolation, it is insufficient for collaboration, where a human and a robot are manipulating in a tightly-coupled shared workspace. Our goal is to make this collaboration fluent and seamless. To this end, we have been developing algorithms where the notion of an observer watching the motion is woven into the fabric of the motion planner. This perspective has allowed us to formalize qualitative notions such as predictability and legibility in psychology in terms of Bayesian inference and inverse optimal control, and to develop generative models for such motion using functional gradient optimization. I will also describe some of our user studies on applying these algorithms to human-robot handovers, 
assistive teleoperation, and shared workspace collaboration, and ongoing work on deception, ambiguity, and emotive motion.
}{
Siddhartha Srinivasa is an Associate Professor at the Robotics Institute at Carnegie Mellon University. His research focuses on manipulation, with the goal of enabling robots to robustly and gracefully interact with the world to perform complex manipulation tasks in uncertain, unstructured, and cluttered environments. His current research focuses on physics-based nonprehensile manipulation for reconfiguring clutter, functional gradient methods for motion planning, and formalizing HRI principles using machine learning, motion planning and optimization algorithms. Sidd is a recipient of the HRI Best Paper Award (2010), ONR Young Investigator Award (2012), Okawa Research Award (2012), and a best-paper finalist at RSS (2012, 2013), IEEE ICRA (2009, 2010, 2012), IEEE IROS (2010), and RO-MAN (2012). Sidd also captains the CMU squash team, and dreams of running ultra-marathons.
}


\invitedTalk{Hadas Kress-Gazit}{High-Level Verifiable Robotics}{Cornell University}{Monday, June 24, 16:30}{kress-gazit.jpg}
{
Why don’t we have robots fetching us coffee and finding our keys for us? While robots have become more capable and powerful, they are not yet integrated into everyday life. Part of the reason for this is that robots are difficult to program and even more difficult to verify. Therefore, to achieve the dream of a robot in every home, two key challenges must be addressed; people should be able to easily interact with robots, and robots must always do as they are told.

In this talk I will discuss the work done in my group to address these challenges. Specifically, I will describe the use of language and temporal logic to capture high-level task specifications and the development of formal methods that take the task specifications and produce correct robot behavior, if such behavior exists.
}{
Hadas Kress-Gazit is an Assistant Professor at the Sibley School of Mechanical and Aerospace Engineering at Cornell University. She received her Ph.D. in Electrical and Systems Engineering from the University of Pennsylvania in 2008 and has been at Cornell since 2009. Her research focuses on formal methods for robotics and automation and more specifically on creating verifiable robot controllers for complex high-level tasks using logic, verification, synthesis, hybrid systems theory and computational linguistics. She received an NSF CAREER award in 2010 and a DARPA Young Faculty Award in 2012.
}
